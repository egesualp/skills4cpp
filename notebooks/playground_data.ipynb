{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeed5bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esualp/miniconda3/envs/thesis/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Welcome to the Data Exploration Guide!\n",
      "ğŸ“ Current separator token: '<SEP>'\n",
      "ğŸ’¡ This notebook will help you understand the data structure step by step\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# ğŸ¯ DATA EXPLORATION NOTEBOOK - Skills4Cpp\n",
    "# ================================================\n",
    "# This notebook helps you understand the data structure and functions\n",
    "# without loading the full (huge) datasets\n",
    "\n",
    "from data import Data\n",
    "from utils import SEP_TOKEN\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "\n",
    "print(\"ğŸš€ Welcome to the Data Exploration Guide!\")\n",
    "print(f\"ğŸ“ Current separator token: '{SEP_TOKEN}'\")\n",
    "print(\"ğŸ’¡ This notebook will help you understand the data structure step by step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f6879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# ğŸ“Š 1. UNDERSTANDING THE DATA STRUCTURE\n",
    "# ================================================\n",
    "print(\"ğŸ“Š 1. UNDERSTANDING THE DATA STRUCTURE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Let's look at what a typical data pair looks likeA\n",
    "sample_doc1 = \"role: Software Engineer \\n description: Develop software<SEP>role: Data Scientist \\n description: Analyze data\"\n",
    "sample_doc2 = \"esco role: Software Developer \\n description: Creates software applications\"\n",
    "\n",
    "print(\"ğŸ” A typical data pair:\")\n",
    "print(f\"ğŸ“„ Document 1 (career history): {sample_doc1}\")\n",
    "print(f\"ğŸ“„ Document 2 (target ESCO occupation): {sample_doc2}\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ” Breaking it down:\")\n",
    "print(\"   â€¢ Document 1: Your career journey (multiple jobs separated by <SEP>)\")\n",
    "print(\"   â€¢ Document 2: The target occupation you might transition to\")\n",
    "print(\"   â€¢ Goal: Learn patterns like 'Software Engineer â†’ Data Scientist â†’ Software Developer'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9f695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# ğŸ­ 2. EXPLORING UTILITY FUNCTIONS\n",
    "# ================================================\n",
    "print(\"ğŸ­ 2. EXPLORING UTILITY FUNCTIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create some sample data to demonstrate functions|\n",
    "sample_pairs = [\n",
    "    (\"role: Software Engineer \\n description: Develop software<SEP>role: Data Scientist \\n description: Analyze data\", \"esco role: Software Developer \\n description: Creates software\"),\n",
    "    (\"role: Teacher \\n description: Teach students<SEP>role: Professor \\n description: Research and teach\", \"esco role: Lecturer \\n description: Delivers lectures\"),\n",
    "    (\"role: Nurse \\n description: Patient care\", \"esco role: Healthcare Assistant \\n description: Provides care\")\n",
    "]\n",
    "\n",
    "print(\"ğŸ” Sample dataset with 3 career examples:\")\n",
    "for i, (doc1, doc2) in enumerate(sample_pairs, 1):\n",
    "    print(f\"\\n{i}. Career Path {i}:\")\n",
    "    print(f\"   Input:  {doc1}\")\n",
    "    print(f\"   Target: {doc2}\")\n",
    "    print()\n",
    "\n",
    "# Demonstrate title extraction\n",
    "print(\"ğŸ“ DEMONSTRATING TITLE EXTRACTION:\")\n",
    "print(\"The _extract_titles function pulls out just the job titles:\")\n",
    "for i, (doc1, doc2) in enumerate(sample_pairs, 1):\n",
    "    roles = re.findall(r\"role: (.*?)\\n\", doc1)\n",
    "    esco_role = re.findall(r\"esco role: (.*?)\\n\", doc2)[0]\n",
    "    print(f\"{i}. {' â†’ '.join(roles)} â†’ {esco_role}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c724b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# ğŸ¯ 3. UNDERSTANDING THE MINUS_LAST FUNCTION\n",
    "# ================================================\n",
    "print(\"ğŸ¯ 3. UNDERSTANDING THE MINUS_LAST FUNCTION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"ğŸ” What does 'minus_last' do?\")\n",
    "print(\"   â€¢ Takes your career history and removes the LAST job\")\n",
    "print(\"   â€¢ Purpose: Create training examples for 'career transition prediction'\")\n",
    "print(\"   â€¢ Example: 'Job1 â†’ Job2 â†’ Job3' becomes 'Job1 â†’ Job2' (predict Job3)\")\n",
    "print()\n",
    "\n",
    "# Demonstrate with our sample data\n",
    "sample_doc1 = \"role: Software Engineer \\n description: Develop software<SEP>role: Data Scientist \\n description: Analyze data<SEP>role: ML Engineer \\n description: Build models\"\n",
    "sample_doc2 = \"esco role: AI Engineer \\n description: Develops AI systems\"\n",
    "\n",
    "print(f\"ğŸ“„ Original career path: {sample_doc1}\")\n",
    "print(f\"ğŸ¯ Target prediction: {sample_doc2}\")\n",
    "print()\n",
    "\n",
    "# Show what minus_last does\n",
    "segments = sample_doc1.split(SEP_TOKEN)\n",
    "print(\"ğŸ” Breaking into segments:\")\n",
    "for i, segment in enumerate(segments, 1):\n",
    "    print(f\"   {i}. {segment}\")\n",
    "\n",
    "print(f\"\\nâœ‚ï¸  After minus_last: {SEP_TOKEN.join(segments[:-1])}\")\n",
    "print(\"ğŸ¯ Still predict: ML Engineer\")\n",
    "print(\"ğŸ’¡ Idea: 'Learn from incomplete career paths to predict the next step'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e1d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# ğŸ—‚ï¸  4. UNDERSTANDING DATASET TYPES\n",
    "# ================================================\n",
    "print(\"ğŸ—‚ï¸  4. UNDERSTANDING DATASET TYPES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"ğŸ” Available Dataset Types:\")\n",
    "print(\"   1. 'decorte' - Anonymous working histories with ESCO annotations\")\n",
    "print(\"   2. 'decorte_esco' - Same as decorte but all experiences in ESCO format\")\n",
    "print(\"   3. 'karrierewege' - Career paths from German job market\")\n",
    "print(\"   4. 'karrierewege_occ' - Karrierewege with occupational info\")\n",
    "print(\"   5. 'karrierewege_100k' - Larger Karrierewege dataset\")\n",
    "print(\"   6. 'karrierewege_cp' - Karrierewege with career path data\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ” Dataset Characteristics:\")\n",
    "print(\"   â€¢ decorte: Real career histories with standardized ESCO occupations\")\n",
    "print(\"   â€¢ karrierewege: German career trajectories with language variants\")\n",
    "print(\"   â€¢ _100k: Larger dataset (100k+ examples)\")\n",
    "print(\"   â€¢ _cp: Career path specific processing\")\n",
    "print(\"   â€¢ _free: Uses free text instead of ESCO format\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ’¡ Key Differences:\")\n",
    "print(\"   â€¢ ESCO format: Standardized job titles with descriptions\")\n",
    "print(\"   â€¢ Free text: Raw job titles and descriptions\")\n",
    "print(\"   â€¢ Size: Some datasets have 100k+ examples (hence the loading time!)\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ§  Memory Strategy:\")\n",
    "print(\"   â€¢ Load only what you need: Use smaller datasets for exploration\")\n",
    "print(\"   â€¢ Work with subsets: Take first N examples for testing\")\n",
    "print(\"   â€¢ Use language variants: 'en_free' datasets are often smaller\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d4f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# ğŸ§ª 5. WORKING WITH SMALL SUBSETS (Smart Testing)\n",
    "# ================================================\n",
    "print(\"ğŸ§ª 5. WORKING WITH SMALL SUBSETS (Smart Testing)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"ğŸ” Why work with subsets?\")\n",
    "print(\"   â€¢ Full datasets are HUGE (100k+ examples)\")\n",
    "print(\"   â€¢ Takes minutes to load, uses lots of memory\")\n",
    "print(\"   â€¢ For development/testing: Small samples are perfect!\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ’¡ Strategy 1: Create your own small dataset\")\n",
    "# Create a tiny dataset for testing\n",
    "tiny_pairs = [\n",
    "    (\"role: Junior Developer \\n description: Entry level coding\", \"esco role: Software Developer \\n description: Creates software\"),\n",
    "    (\"role: Data Analyst \\n description: Work with data\", \"esco role: Data Scientist \\n description: Advanced data analysis\"),\n",
    "    (\"role: Teacher \\n description: Teach students<SEP>role: Principal \\n description: School management\", \"esco role: Education Manager \\n description: Manages educational programs\")\n",
    "]\n",
    "\n",
    "print(\"ğŸ“Š Our tiny test dataset:\")\n",
    "for i, (career, target) in enumerate(tiny_pairs, 1):\n",
    "    print(f\"{i}. {career}\")\n",
    "    print(f\"   â†’ {target}\")\n",
    "    print()\n",
    "\n",
    "print(\"ğŸ’¡ Strategy 2: Load just a few examples\")\n",
    "print(\"   â€¢ Stop loading after N examples\")\n",
    "print(\"   â€¢ Use sampling techniques\")\n",
    "print(\"   â€¢ Perfect for understanding structure without waiting!\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ” Benefits of small datasets:\")\n",
    "print(\"   â€¢ Fast loading (seconds vs minutes)\")\n",
    "print(\"   â€¢ Easy to inspect and understand\")\n",
    "print(\"   â€¢ Perfect for debugging functions\")\n",
    "print(\"   â€¢ Can manually verify correctness\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ§  Pro Tip:\")\n",
    "print(\"   â€¢ Start with 5-10 examples to understand patterns\")\n",
    "print(\"   â€¢ Test your functions on this small set first\")\n",
    "print(\"   â€¢ Then gradually increase size for performance testing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd37f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# ğŸª 6. UNDERSTANDING STAGES & DATA PROCESSING\n",
    "# ================================================\n",
    "print(\"ğŸª 6. UNDERSTANDING STAGES & DATA PROCESSING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"ğŸ” Available stages in get_data():\")\n",
    "print(\"   1. 'embedding_finetuning' - Full career paths for representation learning\")\n",
    "print(\"   2. 'transformation_finetuning' - Career paths with last job removed\")\n",
    "print(\"   3. 'evaluation' - Same as transformation_finetuning\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ¯ What each stage does:\")\n",
    "print(\"   â€¢ embedding_finetuning: Learn general career patterns\")\n",
    "print(\"     Input:  'Job1 â†’ Job2 â†’ Job3' â†’ Target: 'Job4'\")\n",
    "print(\"     Use:   Training embeddings, learning career trajectories\")\n",
    "print()\n",
    "print(\"   â€¢ transformation_finetuning: Learn transition patterns\")\n",
    "print(\"     Input:  'Job1 â†’ Job2' â†’ Target: 'Job3'\")\n",
    "print(\"     Use:   Predicting next career steps, career counseling\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ” ONLY_TITLES parameter:\")\n",
    "print(\"   â€¢ ONLY_TITLES=False: Full descriptions (rich information)\")\n",
    "print(\"   â€¢ ONLY_TITLES=True: Just job titles (simpler, faster)\")\n",
    "print(\"   â€¢ Choose based on your model needs!\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ’¡ Testing stages with our tiny dataset:\")\n",
    "# Simulate what different stages would do\n",
    "career_path = \"role: Developer \\n description: Code<SEP>role: Senior Dev \\n description: Lead teams<SEP>role: Architect \\n description: Design systems\"\n",
    "\n",
    "print(f\"Original: {career_path}\")\n",
    "print(\"Target:   esco role: Tech Lead \\n description: Leads technical teams\")\n",
    "\n",
    "# Simulate different stages\n",
    "segments = career_path.split(SEP_TOKEN)\n",
    "print(f\"\\nğŸ“Š embedding_finetuning: {SEP_TOKEN.join(segments)}\")\n",
    "print(f\"ğŸ¯ transformation_finetuning: {SEP_TOKEN.join(segments[:-1])}\")\n",
    "print(\"ğŸ’¡ Both predict: Architect\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56a09b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# ğŸš€ 7. PRACTICAL NEXT STEPS\n",
    "# ================================================\n",
    "print(\"ğŸš€ 7. PRACTICAL NEXT STEPS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"ğŸ’¡ Now that you understand the structure, here's how to proceed:\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ¯ Step 1: Start with a small, manageable dataset\")\n",
    "print(\"   data = Data('karrierewege_occ', ONLY_TITLES=True)  # Often smaller\")\n",
    "print(\"   # or\")\n",
    "print(\"   data = Data('decorte', ONLY_TITLES=True)  # Good starting point\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ¯ Step 2: Get a subset of data for exploration\")\n",
    "print(\"   train, val, test = data.get_data('embedding_finetuning')\")\n",
    "print(\"   # Work with first 100 examples\")\n",
    "print(\"   small_train = train[:100]\")\n",
    "print(\"   small_val = val[:10]\")\n",
    "print(\"   small_test = test[:10]\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ¯ Step 3: Explore the data structure\")\n",
    "print(\"   print('First training example:')\")\n",
    "print(\"   print(small_train[0])\")\n",
    "print(\"   print('\\\\nLabels in dataset:', len(data.labels))\")\n",
    "print(\"   print('First 5 labels:', data.labels[:5])\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ¯ Step 4: Test different configurations\")\n",
    "print(\"   # Try different stages\")\n",
    "print(\"   train_trans, val_trans, test_trans = data.get_data('transformation_finetuning')\")\n",
    "print(\"   \")\n",
    "print(\"   # Try with full descriptions\")\n",
    "print(\"   data_full = Data('decorte', ONLY_TITLES=False)\")\n",
    "print(\"   train_full, _, _ = data_full.get_data('embedding_finetuning')\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ¯ Step 5: Scale up gradually\")\n",
    "print(\"   # Start with 100, then 1000, then full dataset\")\n",
    "print(\"   # Monitor memory usage and loading time\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ”¥ Pro Tips:\")\n",
    "print(\"   â€¢ Use ONLY_TITLES=True for faster loading and simpler models\")\n",
    "print(\"   â€¢ Start with 'karrierewege_occ' - often smaller than others\")\n",
    "print(\"   â€¢ Use subsets during development, full datasets for final training\")\n",
    "print(\"   â€¢ Monitor memory: Large datasets can use 10GB+ RAM\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ‰ You're ready to explore! The key is starting small and scaling up.\")\n",
    "print(\"ğŸ’¡ Remember: Understanding 100 examples well is better than loading 100k poorly!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ† CONGRATULATIONS! You now understand:\")\n",
    "print(\"   âœ… Data structure (career paths â†’ target occupations)\")\n",
    "print(\"   âœ… Utility functions (minus_last, extract_titles)\")\n",
    "print(\"   âœ… Dataset types and their differences\")\n",
    "print(\"   âœ… Processing stages and their purposes\")\n",
    "print(\"   âœ… Smart strategies for working with large datasets\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebd8a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# ğŸ§ª PRACTICAL EXAMPLE: Working with Small Data\n",
    "# ================================================\n",
    "print(\"ğŸ§ª PRACTICAL EXAMPLE: Working with Small Data\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a mock version of the loading functions to avoid the huge datasets\n",
    "def create_small_test_dataset():\n",
    "    \"\"\"Create a small dataset for testing - simulates what the real functions do\"\"\"\n",
    "    return [\n",
    "        # (career_history, target_occupation)\n",
    "        (\"role: Junior Developer \\n description: Entry level coding<SEP>role: Software Engineer \\n description: Full stack development\",\n",
    "         \"esco role: Senior Developer \\n description: Leads development projects\"),\n",
    "\n",
    "        (\"role: Data Analyst \\n description: Basic data analysis<SEP>role: Business Analyst \\n description: Business insights\",\n",
    "         \"esco role: Data Scientist \\n description: Advanced analytics and modeling\"),\n",
    "\n",
    "        (\"role: Teacher \\n description: Elementary education<SEP>role: Department Head \\n description: Curriculum management\",\n",
    "         \"esco role: Education Manager \\n description: Manages educational programs\"),\n",
    "\n",
    "        (\"role: Nurse \\n description: Patient care<SEP>role: Senior Nurse \\n description: Team coordination\",\n",
    "         \"esco role: Nursing Manager \\n description: Manages nursing staff\"),\n",
    "\n",
    "        (\"role: Sales Rep \\n description: Direct sales<SEP>role: Sales Manager \\n description: Team leadership\",\n",
    "         \"esco role: Sales Director \\n description: Strategic sales planning\")\n",
    "    ]\n",
    "\n",
    "# Simulate the Data class functionality\n",
    "class MockData:\n",
    "    def __init__(self, data_type, ONLY_TITLES=False):\n",
    "        self.data_type = data_type\n",
    "        self.only_titles = ONLY_TITLES\n",
    "        self.train_pairs = create_small_test_dataset()\n",
    "        self.val_pairs = create_small_test_dataset()[:2]  # Just 2 for validation\n",
    "        self.test_pairs = create_small_test_dataset()[:1]  # Just 1 for testing\n",
    "        self.labels = list(set([pair[1] for pair in self.train_pairs + self.val_pairs + self.test_pairs]))\n",
    "\n",
    "    def get_data(self, stage):\n",
    "        if stage == 'embedding_finetuning':\n",
    "            if self.only_titles:\n",
    "                return self._extract_titles(self.train_pairs), self._extract_titles(self.val_pairs), self._extract_titles(self.test_pairs)\n",
    "            else:\n",
    "                return self.train_pairs, self.val_pairs, self.test_pairs\n",
    "        elif stage in ['transformation_finetuning', 'evaluation']:\n",
    "            if self.only_titles:\n",
    "                return self._minus_last(self._extract_titles(self.train_pairs)), self._minus_last(self._extract_titles(self.val_pairs)), self._minus_last(self._extract_titles(self.test_pairs))\n",
    "            else:\n",
    "                return self._minus_last(self.train_pairs), self._minus_last(self.val_pairs), self._minus_last(self.test_pairs)\n",
    "\n",
    "    @staticmethod\n",
    "    def _minus_last(data_pairs):\n",
    "        \"\"\"Remove last segment from career histories\"\"\"\n",
    "        result = []\n",
    "        for doc1, doc2 in data_pairs:\n",
    "            segments = doc1.split(SEP_TOKEN)\n",
    "            if len(segments) > 1:\n",
    "                new_doc1 = SEP_TOKEN.join(segments[:-1])\n",
    "                result.append((new_doc1, doc2))\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_titles(data_pairs):\n",
    "        \"\"\"Extract just the job titles\"\"\"\n",
    "        result = []\n",
    "        for doc1, doc2 in data_pairs:\n",
    "            roles = re.findall(r\"role: (.*?)\\n\", doc1)\n",
    "            esco_role = re.findall(r\"esco role: (.*?)\\n\", doc2)[0]\n",
    "            result.append((SEP_TOKEN.join(roles), esco_role))\n",
    "        return result\n",
    "\n",
    "# Test it!\n",
    "print(\"ğŸ” Creating a small mock dataset (5 examples)...\")\n",
    "mock_data = MockData('decorte', ONLY_TITLES=False)\n",
    "\n",
    "print(f\"âœ… Created dataset with {len(mock_data.train_pairs)} training examples\")\n",
    "print(f\"ğŸ“Š Validation set: {len(mock_data.val_pairs)} examples\")\n",
    "print(f\"ğŸ§ª Test set: {len(mock_data.test_pairs)} examples\")\n",
    "print(f\"ğŸ·ï¸  Unique labels: {len(mock_data.labels)}\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ” Let's look at the first example:\")\n",
    "train, val, test = mock_data.get_data('embedding_finetuning')\n",
    "print(f\"Training example 1: {train[0]}\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ¯ Now try with ONLY_TITLES=True:\")\n",
    "mock_data_titles = MockData('decorte', ONLY_TITLES=True)\n",
    "train_titles, val_titles, test_titles = mock_data_titles.get_data('embedding_finetuning')\n",
    "print(f\"Title-only example: {train_titles[0]}\")\n",
    "print()\n",
    "\n",
    "print(\"âœ‚ï¸  Try transformation_finetuning (removes last job):\")\n",
    "train_trans, _, _ = mock_data.get_data('transformation_finetuning')\n",
    "print(f\"After minus_last: {train_trans[0]}\")\n",
    "print(\"ğŸ’¡ Notice: 'Software Engineer' was removed, still predict 'Senior Developer'\")\n",
    "\n",
    "print(\"\\nğŸ‰ Success! Now you can experiment without loading huge datasets!\")\n",
    "print(\"ğŸ’¡ Use this approach for quick testing and understanding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5348fe61",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mData\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkarrierewege+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m train, val, test \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_finetuning\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(train)\n",
      "File \u001b[0;32m~/repos/skills4cpp/src/data.py:45\u001b[0m, in \u001b[0;36mData.__init__\u001b[0;34m(self, DATA_TYPE, DOC_1_PROMPT, DOC_2_PROMPT, ONLY_TITLES, max_rows)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/skills4cpp/src/data.py:80\u001b[0m, in \u001b[0;36mData.__load_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_pairs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_pairs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_pairs \u001b[38;5;241m=\u001b[39m load_prepare_karrierewege(\n\u001b[1;32m     76\u001b[0m         consider_all_subspans_of_len_at_least_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, minus_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men_free_cp\u001b[39m\u001b[38;5;124m'\u001b[39m, max_rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_rows\n\u001b[1;32m     77\u001b[0m     )\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Extract unique labels from the dataset\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m([pair[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_pairs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_pairs\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_pairs]))\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "data = Data('karrierewege+', max_rows = 1000)\n",
    "train, val, test = data.get_data('embedding_finetuning')\n",
    "df_train = pd.DataFrame(train)\n",
    "df_train.iloc[1]\n",
    "df_train.info()\n",
    "print(\"\\n\".join(df_train.iloc[1].to_list()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17868e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 4627.02it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 4714.71it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 4658.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 853 entries, 0 to 852\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       853 non-null    object\n",
      " 1   1       853 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 13.5+ KB\n",
      "                                                   0  \\\n",
      "0  role: Line Cook \\n description: - Prepped food...   \n",
      "1  role: Line Cook \\n description: - Prepared foo...   \n",
      "2  role: Line Chef \\n description: - Prepared foo...   \n",
      "3  role: Line Cook \\n description: - Prepped food...   \n",
      "4  role: Line Cook \\n description: - Prepared foo...   \n",
      "\n",
      "                                                   1  \n",
      "0  esco role: cook \\n description: Cooks are culi...  \n",
      "1  esco role: head chef \\n description: Head chef...  \n",
      "2  esco role: head chef \\n description: Head chef...  \n",
      "3  esco role: head chef \\n description: Head chef...  \n",
      "4  esco role: head chef \\n description: Head chef...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from data import Data\n",
    "from utils import SEP_TOKEN\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "\n",
    "# import DECORTE\n",
    "# The DATA_TYPE is case-sensitive, so it should be 'decorte'\n",
    "decorte_data = Data('decorte', max_rows=100)\n",
    "train_decorte, val_decorte, test_decorte = decorte_data.get_data('embedding_finetuning')\n",
    "df_decorte_train = pd.DataFrame(train_decorte)\n",
    "df_decorte_train.info()\n",
    "print(df_decorte_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a767455",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decorte_train.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d22425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
