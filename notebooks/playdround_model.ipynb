{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f3ea7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fde6cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esualp/miniconda3/envs/thesis/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c282b6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download from the ðŸ¤— Hub\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "# Run inference\n",
    "sentences = [\n",
    "    'Volksvertreter',\n",
    "    'Parlamentarier',\n",
    "    'OberbÃ¼rgermeister',\n",
    "]\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd136e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download from the ðŸ¤— Hub\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "# Run inference\n",
    "sentences = [\n",
    "    'Volksvertreter',\n",
    "    'Parlamentarier',\n",
    "    'OberbÃ¼rgermeister',\n",
    "]\n",
    "embeddings = model.encode(sentences, normalize_embeddings=True)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a799169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import BiEncoder \n",
    "import numpy as np\n",
    "\n",
    "def test_normalization_flag(base_config):\n",
    "    \"\"\"Test that the normalize_output flag works correctly.\"\"\"\n",
    "    # Test with normalization ON\n",
    "    base_config.model.proj_dim = None # No projection for simplicity\n",
    "    model_norm = BiEncoder(base_config.model, base_config.device)\n",
    "    \n",
    "    job_titles = [\"Data Scientist\"]\n",
    "    job_embs_norm = model_norm.encode_job(job_titles, normalize=True)\n",
    "    \n",
    "    # Check that the L2 norm is close to 1\n",
    "    norm = np.linalg.norm(job_embs_norm, axis=1)\n",
    "    assert np.allclose(norm, 1.0), \"Embeddings should be normalized\"\n",
    "\n",
    "    # Test with normalization OFF\n",
    "    model_no_norm = BiEncoder(base_config.model, base_config.device)\n",
    "\n",
    "    job_embs_no_norm = model_no_norm.encode_job(job_titles, normalize=False)\n",
    "\n",
    "    # Check that the L2 norm is NOT 1\n",
    "    norm_unnormalized = np.linalg.norm(job_embs_no_norm, axis=1)\n",
    "    assert not np.allclose(norm_unnormalized, 1.0), \"Embeddings should not be normalized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e96b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_config(dummy_data_files):\n",
    "    \"\"\"A base config that can be modified by other fixtures.\"\"\"\n",
    "    pairs_path, esco_path = dummy_data_files\n",
    "    return Config(\n",
    "        seed=42,\n",
    "        device=\"cpu\",\n",
    "        model=ModelConfig(\n",
    "            hf_id=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            proj_dim=None,\n",
    "            asymmetric=False,\n",
    "            normalize_output=True,\n",
    "        ),\n",
    "        data=DataConfig(pairs_path=pairs_path, esco_titles_path=esco_path),\n",
    "        infer=InferConfig(batch_size=32, topk=5),\n",
    "        artifacts=ArtifactsConfig(run_dir=\"runs/test\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c28ecba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import Config, ModelConfig, DataConfig, InferConfig, ArtifactsConfig\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "# Create dummy files for the config\n",
    "temp_dir = tempfile.gettempdir()\n",
    "pairs_path = os.path.join(temp_dir, \"dummy_pairs.jsonl\")\n",
    "esco_path = os.path.join(temp_dir, \"dummy_esco.jsonl\")\n",
    "\n",
    "with open(pairs_path, \"w\") as f:\n",
    "    f.write('{\"skill\": \"python\", \"job\": \"Data Scientist\"}\\n')\n",
    "\n",
    "with open(esco_path, \"w\") as f:\n",
    "    f.write('{\"title\": \"Data Scientist\"}\\n')\n",
    "\n",
    "dummy_data_files = (pairs_path, esco_path)\n",
    "\n",
    "def create_base_config(dummy_data_files):\n",
    "    \"\"\"A base config that can be modified by other fixtures.\"\"\"\n",
    "    pairs_path, esco_path = dummy_data_files\n",
    "    return Config(\n",
    "        seed=42,\n",
    "        device=\"cpu\",\n",
    "        model=ModelConfig(\n",
    "            hf_id=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            proj_dim=None,\n",
    "            asymmetric=False,\n",
    "            normalize_output=False,\n",
    "        ),\n",
    "        data=DataConfig(pairs_path=pairs_path, esco_titles_path=esco_path),\n",
    "        infer=InferConfig(batch_size=32, topk=5),\n",
    "        artifacts=ArtifactsConfig(run_dir=\"runs/test\"),\n",
    "    )\n",
    "\n",
    "base_conf = create_base_config(dummy_data_files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d04952b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Embeddings should not be normalized",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtest_normalization_flag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_conf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mtest_normalization_flag\u001b[39m\u001b[34m(base_config)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Check that the L2 norm is NOT 1\u001b[39;00m\n\u001b[32m     23\u001b[39m norm_unnormalized = np.linalg.norm(job_embs_no_norm, axis=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.allclose(norm_unnormalized, \u001b[32m1.0\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mEmbeddings should not be normalized\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: Embeddings should not be normalized"
     ]
    }
   ],
   "source": [
    "test_normalization_flag(base_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc36811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import BiEncoder \n",
    "import numpy as np\n",
    "\n",
    "def test_normalization_flag(base_config):\n",
    "    \"\"\"Test that the normalize_output flag works correctly.\"\"\"\n",
    "    # Test with normalization ON\n",
    "    base_config.model.proj_dim = None # No projection for simplicity\n",
    "    model_norm = BiEncoder(base_config.model, base_config.device)\n",
    "    \n",
    "    job_titles = [\"Data Scientist\"]\n",
    "    job_embs_norm = model_norm.encode_job(job_titles, normalize=True)\n",
    "    \n",
    "    # Check that the L2 norm is close to 1\n",
    "    norm = np.linalg.norm(job_embs_norm, axis=1)\n",
    "    assert np.allclose(norm, 1.0), \"Embeddings should be normalized\"\n",
    "\n",
    "    # Test with normalization OFF\n",
    "    model_no_norm = BiEncoder(base_config.model, base_config.device)\n",
    "\n",
    "    job_embs_no_norm = model_no_norm.encode_job(job_titles, normalize=False)\n",
    "\n",
    "    # Check that the L2 norm is NOT 1\n",
    "    norm_unnormalized = np.linalg.norm(job_embs_no_norm, axis=1)\n",
    "    assert not np.allclose(norm_unnormalized, 1.0), \"Embeddings should not be normalized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "600b32a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_conf.model.proj_dim = None # No projection for simplicity\n",
    "model_norm = BiEncoder(base_conf.model, base_conf.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce7191b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = [\"Data Scientist\"]\n",
    "job_embs_norm = model_norm.encode_job(job_titles, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "160f8fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = np.linalg.norm(job_embs_norm, axis=1)\n",
    "assert np.allclose(norm, 1.0), \"Embeddings should be normalized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8700723",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_norm = BiEncoder(base_conf.model, base_conf.device)\n",
    "\n",
    "job_embs_no_norm = model_no_norm.encode_job(job_titles, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "696e65c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiEncoder(\n",
       "  (st_model): SentenceTransformer(\n",
       "    (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "    (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "    (2): Normalize()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a383b6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Embeddings should not be normalized",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Check that the L2 norm is NOT 1\u001b[39;00m\n\u001b[32m      2\u001b[39m norm_unnormalized = np.linalg.norm(job_embs_no_norm, axis=\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.allclose(norm_unnormalized, \u001b[32m1.0\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mEmbeddings should not be normalized\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: Embeddings should not be normalized"
     ]
    }
   ],
   "source": [
    "# Check that the L2 norm is NOT 1\n",
    "norm_unnormalized = np.linalg.norm(job_embs_no_norm, axis=1)\n",
    "assert not np.allclose(norm_unnormalized, 1.0), \"Embeddings should not be normalized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31c404f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8529d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Drop the last module (Normalize)\n",
    "model._modules.pop(str(len(model._modules)-1))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59a39295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With normalization:\n",
      "  Text 0: norm = 1.0000\n",
      "  Text 1: norm = 1.0000\n",
      "\n",
      "Without normalization:\n",
      "  Text 0: norm = 1.0000\n",
      "  Text 1: norm = 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Load a pretrained model (with Normalize layer in its architecture)\n",
    "model =  SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "texts = [\"This is a test sentence.\", \"Another sentence to encode.\"]\n",
    "\n",
    "# Encode with normalization\n",
    "emb_norm = model.encode(texts, normalize_embeddings=True)\n",
    "# Encode without normalization\n",
    "emb_raw = model.encode(texts, normalize_embeddings=False)\n",
    "\n",
    "# Check L2 norms\n",
    "print(\"With normalization:\")\n",
    "for i, e in enumerate(emb_norm):\n",
    "    print(f\"  Text {i}: norm = {np.linalg.norm(e):.4f}\")\n",
    "\n",
    "print(\"\\nWithout normalization:\")\n",
    "for i, e in enumerate(emb_raw):\n",
    "    print(f\"  Text {i}: norm = {np.linalg.norm(e):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d886719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False, 'architecture': 'MPNetModel'})\n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e11bdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
